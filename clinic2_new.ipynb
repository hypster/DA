{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression of real estate data\n",
    "For this problem, you will analyze some real estate data. The dataset contains multiple listing service (MLS) real estate transactions for houses sold in 2015-16. We are primarily interested in regressing the `SoldPrice` on the house attributes (`property size`, `house size`, `number of bedrooms`, etc...).\n",
    "\n",
    "Tasks 2.1-2.3 cover the EDA part on the data, therefore not graded. However, they are considered important part of the process. The goal is to work on these tasks either as a group or individually and share good advice with each other on how to proceed. In the process, we expect that you develop some intuition about the data and explanations \n",
    "\n",
    "\n",
    "### Task 2.1: Import the data (already done :))\n",
    "Use the [`pandas.read_csv()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html) function to import the dataset (`houses.csv`). This pandas dataframe will be used for data exploration and linear regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports and setup \n",
    "import pandas as pd\n",
    "import scipy as sc\n",
    "import numpy as np\n",
    "\n",
    "import statsmodels.formula.api as sm\n",
    "\n",
    "#%matplotlib notebook\n",
    "import matplotlib.pyplot as plt \n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline  \n",
    "plt.rcParams['figure.figsize'] = (10, 6) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(348, 21)\n"
     ]
    }
   ],
   "source": [
    "h = pd.read_csv('housespp.csv',index_col=0) #load data\n",
    "print(h.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.2: Clean the data \n",
    "\n",
    "1. There are 21 different variables associated with each of the 348 houses in this dataset. Skim them and try to get a rough understanding of what information this dataset contains. Here is an explanation of the variables.\n",
    "\n",
    "'Access': status of the road to the property (asphalt, concrete etc.)<br>\n",
    "'Acres': total area of the property in acres (acc. to Wikipedia \"an acre may be declared as exactly 4,046.8564224<br> square metres\")\n",
    "'AirType': air-conditioning provider type (e.g. central, electric etc.)<br>\n",
    "'Amenities': extra things available (e.g. cable tv, etc.) <br>\n",
    "'DaysOnMkt': days that the property stayed on the market <br>\n",
    "'Deck': how many floors <br>\n",
    "'GaragCap': # of paring spots <br>\n",
    "'Heat': heating type (e.g. electric, gas, etc.) <br>\n",
    "'Latitude': location info (hint: we are in the USA but where?) <br>\n",
    "'Longitude': location info (hint: we are in the USA but where?) <br>\n",
    "'LstPrice': listed price <br>\n",
    "'Patio': # of patios <br>\n",
    "'PkgSpacs': # of parking spaces <br>\n",
    "'PropType': property type (condo, single family, townhouse, ...) <br>\n",
    "'Roof': type of roof (flat, asphalt, etc.) <br>\n",
    "'SoldPrice': actual price that listing was sold <br>\n",
    "'Taxes': taxes paid <br>\n",
    "'TotBed': # of bedrooms <br>\n",
    "'TotBth': # of bathrooms <br>\n",
    "'TotSqf': area of the house in square feet <br>\n",
    "'YearBlt': year built <br>\n",
    "\n",
    "+ Only keep houses with List Price between 200,000 and 1,000,000 dollars. This is an arbitrary choice and we realize that some people are high rollers, but for our purposes we'll consider the others as outliers. \n",
    "\n",
    "+ As a minimal and required step, we are going to keep the following columns. However, for the last task (2.6) you are free to epxlore how other attributes affect the performance as well. But don't go crazy and avoid overfitting!\n",
    "\n",
    "`['Acres', 'Deck', 'GaragCap', 'Latitude', 'Longitude', 'LstPrice', 'Patio', 'PkgSpacs', 'PropType', 'SoldPrice', 'Taxes', 'TotBed', 'TotBth', 'TotSqf', 'YearBlt']` \n",
    "\n",
    "+ Check the datatypes and convert any numbers that were read as strings to numerical values. (Hint: You can use [`str.replace()`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.str.replace.html) to work with strings.) If there are any categorical values you're interested in, just make sure you include them as you find fit. In particular, convert 'TotSqf' to an integer and add a column titled `Prop_Type_num` that is \n",
    "$$\n",
    "\\text{Prop_Type_num}_i = \\begin{cases} \n",
    "0 & \\text{if $i$-th listing is a condo or townhouse} \\\\\n",
    "1 & \\text{if $i$-th listing is a single family house}\n",
    "\\end{cases}. \n",
    "$$\n",
    "+ Remove the listings with erroneous `Longitude` (one has Longitude = 0) and `Taxes` values (two have unreasonably large values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.3: Exploratory data analysis \n",
    "\n",
    "1. Explore the dataset. Write a short description of the dataset describing the number of items, the number of variables and check to see if the values are reasonable. \n",
    "\n",
    "+ Make a bar chart showing the breakdown of the different types of houses (single family, townhouse, condo). \n",
    "\n",
    "+ Compute the correlation matrix and use a heat map to visualize the correlation coefficients. \n",
    "    - Use a diverging color scale from -1 to +1 (see `vmin` and `vmax` parameters for [pcolor](https://matplotlib.org/devdocs/api/_as_gen/matplotlib.pyplot.pcolor.html))\n",
    "    - Show a legend\n",
    "    - Make sure the proper labels are visible and readable (see [`xticks`](https://matplotlib.org/devdocs/api/_as_gen/matplotlib.pyplot.xticks.html) and the corresponding [`yticks`](https://matplotlib.org/devdocs/api/_as_gen/matplotlib.pyplot.yticks.html).\n",
    "\n",
    "+ Make a scatter plot matrix to visualize the correlations. Color-code the dots by property type. For the plot, only use a subset of the columns: `['Acres', 'LstPrice', 'SoldPrice', 'Taxes', 'TotBed', 'TotBth', 'TotSqf', 'YearBlt']`. Determine which columns have strong correlations. \n",
    "\n",
    "+ Describe your findings with each other and share useful insights for the modeling part (to follow)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Interpretation:** TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DELIVERABLES (DEADLINE 5/March late night, wildcards possible)\n",
    "\n",
    "Honor code applies from these tasks onwards (only individual work)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions for the deliverable: \n",
    "\n",
    "* The tasks that are graded are 2.4-2.6. However, include your work in tasks 2.1-2.3. While, It is not graded, but it's important to include any preprocessing steps you have done, any decisions you made etc.\n",
    "\n",
    "* Make sure that you include a proper amount/mix of comments, results and code.\n",
    "\n",
    "* In the end, make sure that all cells are executed properly and everything you need to show is in your (execucted) notebook.\n",
    "\n",
    "* You are asked to deliver **only your executed notebook file, .ipnyb** and nothing else. Enjoy!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.4: Simple  Linear Regression \n",
    "Use the `ols` function from the [statsmodels](http://www.statsmodels.org/stable/index.html) package to regress the Sold price on some of the other variables (feel free to include all of them, however your work here should be based on the EDA you have done). Your model should be of the form:\n",
    "$$\n",
    "\\text{Sold Price} = \\beta_0 + \\beta_1 x, \n",
    "$$\n",
    "where $x$ is one of the other variables. \n",
    "\n",
    "You'll find that the best predictor of sold price is the list price. Report the $R^2$ value for this model (`SoldPrice ~ LstPrice`) and give an interpretation for its meaning. Also give an interpretation of $\\beta_1$ for this model. Make a scatterplot of list price vs. sold price and overlay the prediction coming from your regression model.\n",
    "\n",
    "Let's put categorical variables into play! We will distinguish between single family houses on the one hand and townhouses and condos on the other hand (so using the `Prop_Type_num` variable you constructed in 2.2). Consider the two regression models: \n",
    "$$\n",
    "\\text{SoldPrice} = \\beta_0 + \\beta_1 \\times \\text{Prop_Type_num}\n",
    "$$\n",
    "and \n",
    "$$\n",
    "\\text{SoldPrice} = \\beta_0  + \\beta_1 \\times \\text{Prop_Type_num} + \\beta_2 \\times \\text{TotSqf}\n",
    "$$\n",
    "\n",
    "What happens with the significance of the `Prop_Type_num` coefficient when we consider the first and the second model? How do you explain this (hint: confounders)? Make a scatterplot of `TotSqf` vs. `SoldPrice` where the house types are colored differently to illustrate your explanation.\n",
    "\n",
    "REMARK: For part 2.4 you do not need to apply cross-validation or regularization or a more complex model (that comes in part 2.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Interpretation:** TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.5: Multilinear Regression \n",
    "Develop a multilinear regression model for house prices in this neighborhood. We could use this to come up with a list price for houses coming on the market, so do not include the list price in your model and, for now, ignore the categorical variable `Prop_Type` (or `Prop_Type_num`). Your model should be of the form:\n",
    "$$\n",
    "\\text{Sold Price} = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\cdots +  \\beta_n x_n, \n",
    "$$\n",
    "where $x_i$ are predictive variables. Which variables are the best predictors for the Sold Price? \n",
    "\n",
    "Specific questions (feel free to extend the scope of your analysis):\n",
    "1. Often the price per square foot for a house is advertised. Is this what the coefficient for `TotSqf` is measuring? Provide an interpretation for the coefficient for `TotSqf`.  \n",
    "+ Estimate the value that each Garage space adds to a house. \n",
    "+ Does latitude or longitude have an impact on house price? Explain. \n",
    "\n",
    "REMARK: For part 2.5 you do not need to apply cross-validation or regularization or a more complex model (that comes in part 2.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Interpretation:** TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.6: Deliver a robust model, where you have included an analysis of all variables etc.\n",
    "\n",
    "If we wanted to start a 'house flipping' company, we'd have to be able to do a better job of predicting the sold price than the list price does. How does your model compare?\n",
    "\n",
    "Based on the exploration in the tasks above, build and deliver a robust model for predicting the sold price. As a minimal and required step here, you need to use cross-validation and regularization and demonstrate their effect on the model.\n",
    "\n",
    "Once you have such a model, you are free to explore any other models you want (also beyond the scope of the course), however that is not necessary. You are not going to be judged on the performance of your model, but on the methodology you followed to build your model and the interpretation of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Interpretation:** TODO"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
